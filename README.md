# Connect
Making the deaf sound through computer vision

## Inspiration
Hearing loss can affect a person in three main ways:
(i) Fewer educational and job opportunities due to impaired communication
(ii)Social withdrawal due to reduced access to services and difficulties communicating with others
(iii)Emotional problems caused by a drop in self-esteem and confidence.

## What it does
We aim to streamline the signing process to better help our hearing-impaired workers to better integrate their workplace especially during work meetings whereby body language significantly improves quality of meeting, and hence empowering our target audience.

Our clients would be targeted towards social entrepreneurs that aims to empower people with hearing disabilities by providing them jobs. Often work meetings might be slowed down and inconvenient if it requires a sign language translator to be present, or if the worker has to write down their thoughts instead of communicating it directly.

## How we built it
Datasets were collected according to the American Sign Language. 
Dataset curated were then trained on a model on TensorFlow and Keras. 
Model trained has hits about 80% accuracy of interpreting sign language. 

## Challenges we ran into
The Dataset we created only has A-Z datasets, and not full  sentences. Further development is needed. 
This is curated for english language only, other languages can be used but need to develop another datasets.

## Accomplishments that we're proud of
We manage to achieve what we envision, to bridge the gap for social good through technology.

## What's next for Connect
Collaboration with Zoom, Google meet, skype, if we manage to develop an elaborated sign language to text model.

## References
https://github.com/cgoxo/hand-sign-recognition/blob/main/README.md

## Team: 
Database and Training Model: Sparsh, Cynthia, Yi Xuan 
Ideation: Sparsh, Cynthia, Yi Xuan, Yesenia
Slide decks and pitching: Yesenia, Yi Xuan
